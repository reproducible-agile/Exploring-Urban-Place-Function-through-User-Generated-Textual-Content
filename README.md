This study employs two datasets: OSM POIs and Wikipedia article summaries. The OSM dataset provides very short textual data in the form of tags, which essentially represent the category of what is located at that position. Wikipedia articles can vary quite substantially in their length and structure. Our analysis is limited to the summaries of geo-located Wikipedia pages, which are more homogenous while still providing key information about the represented object. 
We conduct a series of NLP techniques on the collected datasets and developed a methodological framework that can work to extract place functional information from them. The code for data collection are given as seperate files.
We have first adopted the classic Topic Modelling approaches, running them individually on each datasets. This includes LDA (Blei et al., 2003) and BTM (Yan et al., 2013). The cods to run the classic approaches are added here. Then a neural Topic Modelling approach, BERTopic (Grootendorst, 2022) was applied seperately on each datasets. Codes for running BERTopic is also provided here. The ways to evaluate the performance of the Topic Models are provided within the codes. 
We also leveraged some LLMs in place functional topic label generation from Wikipedia datasets. The code to run each of them are also provided here
Lastly, depending upon the quality of the performance of each method, a combination of best-performing method was adopted on a combined dataset of OSM and Wiki and the final place function label are represented.
